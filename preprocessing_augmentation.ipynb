{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "import rasterio as rio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the full images\n",
    "We load train and test data, rebuild the full images using the merge_raster.py file and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"glaciers_mapping_downsampled\"\n",
    "data_paths = {}\n",
    "\n",
    "#build paths for each pipeline\n",
    "for pipeline in [\"train\", \"test\"]:\n",
    "    for date in [0,1]:\n",
    "        data_paths[f\"{pipeline}{date}\"] = f\"{file_path}/{pipeline}/date{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct full images\n",
    "for key, path in data_paths.items():\n",
    "    output_path = f\"{file_path}/{key}_merged.tif\"\n",
    "    # Execute the command to merge rasters using subprocess and save them\n",
    "    command = [\"python\", \"glaciers_mapping_downsampled/merge_rasters.py\", \"-i\", path, \"-o\", output_path]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the RGB images in png to be able to observe them and (maybe) dras useful conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_paths.keys():\n",
    "    img_path = f\"{file_path}/{key}_merged\"\n",
    "    img = rio.open(f\"{img_path}.tif\").read()\n",
    "    normalized_image = (img - np.min(img)) / (\n",
    "                            np.max(img) - np.min(img)) # maybe not the best way to normalize?\n",
    "    rgb_image = (normalized_image[:3] * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "    pil_image = Image.fromarray(rgb_image)\n",
    "    save_path = f\"full_rgb_images/{key}.png\"\n",
    "    pil_image.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the patches in dictionaries : {( (position_x_of_patch, position_y_of_patch) : numpy_array_of_the_patch )}\n",
    "\n",
    "At this stage the np array of patches are of dimension (band, pixel_x, pixel_y) i.e. (4,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1768/1768 [00:19<00:00, 88.77it/s] \n",
      "100%|██████████| 1768/1768 [00:14<00:00, 123.22it/s]\n",
      "100%|██████████| 351/351 [00:02<00:00, 144.85it/s]\n",
      "100%|██████████| 351/351 [00:02<00:00, 143.96it/s]\n",
      "100%|██████████| 1768/1768 [00:05<00:00, 318.99it/s]\n",
      "100%|██████████| 351/351 [00:00<00:00, 441.72it/s]\n"
     ]
    }
   ],
   "source": [
    "patches_train0 = get_organized_dict_of_patches(f\"{data_paths['train0']}\")\n",
    "patches_train1 = get_organized_dict_of_patches(f\"{data_paths['train1']}\")\n",
    "patches_test0 = get_organized_dict_of_patches(f\"{data_paths['test0']}\")\n",
    "patches_test1 = get_organized_dict_of_patches(f\"{data_paths['test1']}\")\n",
    "\n",
    "patches_train_gt = get_organized_dict_of_patches(\"glaciers_mapping_downsampled/train/gt\")\n",
    "patches_test_gt = get_organized_dict_of_patches(\"glaciers_mapping_downsampled/test/gt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128, 128)\n",
      "(1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(patches_test0[(1,3)].shape) #shape of test patch 1_3 \n",
    "print(patches_test_gt[(1,3)].shape) #shape of test ground ruth patch 1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEOenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
